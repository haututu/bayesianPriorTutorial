---
title: "Example construction of informative Bayesian priors for substance research with minority groups"
author: "Taylor Winter"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
opts_chunk$set(echo = TRUE)

theme_set(theme_classic())
```

## Overview

This document is a walkthrough for an associated tutorial manuscript in review with the journal Addiction[^1] and accompanies `R` code in the following [GitHub repository](https://github.com/haututu/bayesianPriorTutorial). We use a large dataset to investigate if sexual minorities (SMs) are at higher risk of psychological distress relative to non-SMs (nSMs). We then constract priors based on the large survey model and run a similar model using a smaller survey. Lastly, we use priors to inform part of a mediation analysis to get a more reliable understanding on how much stress can mediate the increased likelihood of hazarous drinking expressed by SMs relative to nSMs. 

In the associated manuscript, we used the [National Survey on Drug Use and Health](https://nsduhweb.rti.org/respweb/homepage.cfm) (NSDUH; n=83,661) to inform our smaller survey, the [New Zealand Health Survey](https://www.health.govt.nz/nz-health-statistics/national-collections-and-surveys/surveys/new-zealand-health-survey) (NZHS, n=24098). In the former case, the dataset is huge, and in the latter, the data is provided by application only. Hence, we have created created smaller datasets that will show similar trends as presented in our study albeit with slightly different coefficients (See `makeSyntheticData.R` for details on how we created datasets).

The analysis relies on the `tidyverse` and a Bayesian regression package called `brms`[^2]. This document does not cover these packages and we would encourage readers to consult the `brms` vignettes or any basic R tutorials for `tidyverse` walkthroughs.

[^1]: Winter, T., Riordan, B., Surace, A., & Jose, P. (In Review). A comparison of Bayesian and classical statistics for substance research with sexual minorities

[^2]: Paul-Christian BÃ¼rkner (2017). brms: An R Package for Bayesian Multilevel Models Using Stan. Journal of
  Statistical Software, 80(1), 1-28. doi:10.18637/jss.v080.i01

## Modelling the United States data (NSDUH)

We start with the script named `usModel.R`, by loading the neccesary libraries and the `syntheticUs.RDS` file. You can now check and plot the data if you wish. The data contains five variables:

1. SEXIDENT - Sexual identity; Heterosexual (1), Homosexual (2), or Bisexual(3)
2. AGE2 - A ordinal variable with different age groupings (labels attached to variable)
3. IRFAMIN3 - Total family income as an ordinal variable (labels attached to variable)
4. IRSEX - Categorical variable either male (1) or female (2)
5. SPDMON - Is a binomial variable denoting an experience of psychological distress in the last six months, either no stress (0) or stress (1)

```{r readUs, message=FALSE}
library(tidyverse)
library(brms)

syntheticUs <- readRDS("data/syntheticUs.RDS") %>%
  sample_frac(0.4)
```

### Constructing priors

We then construct some simple weak priors for the logistic regression, this is out of neccesity because the dataset is so huge in our study that it would take a day to run. When using Stan as your MCMC sampler, even very week priors can have a major impact on your convergence time without influencing your posterior at all.

We are specifying priors as normal distributions, for example the coefficient `IRSEX2` has a normal distrtribution with a mean of one and standard deviation of one (note the scale is log odds for logistic regression). This means we believe the odds of females having higher stress than males has 95% probability of falling between an odds of 0.14 and 7.38... it shoudl be particularly obvious why this prior would not impact on our posterior but certainly rules out a large range of increadibly unlikely odds ratios.

A further point you may note below, is that the age and income vairables start with `mo~`. This is short for monotonic, which is a type of mathematical function that allows you to model ordered variables. As we are using monotonic functions in our `brms` model, our variables gain the `mo~` prefix. Similarly, as sex is a categorical variable, the effect of females is modelled in reference to males and we therefore add the suffix `~2` to acknowledge this fact.


```{r priorsUs}
priors <- c(prior("normal(1, 1)", coef="IRSEX2"),
            prior("normal(-1, 1)", coef="moAGE2"),
            prior("normal(-1, 1)", coef="moIRFAMIN3"))

```

### Basic model

We can now model the US data. If you're familiar with `lme4` syntax then this is quite straight forward, we model stress (SPDMON) as a covariate with age (AGE2), sex (IRSEX), SM status (sexident), and family income (IRFAMIN3) as predictors. As mentioned, age and family income are ordinal variables and we capture this relationship by modelling a  monotonic effect, implemented by wrapping the variable with the `mo()` function.

We then specify the family (response distribution), in this case we want a Bernoulli distribution which will conduct a traditional logistic regression. We parse our priors, and want to sample four chains across four CPU cores. It will take about five minutes to run. Feel free to reflect on our pain when running a sample of over 80,000 during this time.

```{r modelUs, cache=TRUE}
brms.us <- brm(
  SPDMON ~ mo(AGE2) + IRSEX * SEXIDENT + mo(IRFAMIN3),
  family = bernoulli(),
  prior = prior("normal(0, 2)", class="b"),
  cores = 4,
  chains = 4,
  data=syntheticUs
  )
```

Finally, we can see the results of our logistic regression using the `summary(brms.us)` function. It will output a bunch of simplex parameters which are pertaining to our monotonic effects, feel free to ignore them and focus on the population-level effects for the purpose of this walkthrough. The population-level effects that will form the basis of our priors for the NZ data. You will see in the table below we have extracted only the fixed effects (Table 1).

```{r fixef, echo=FALSE}
fixef(brms.us) %>%
  kable(caption = "<b>Table 1.</b> Fixed effects for the logistic regression model using US data") %>%
  kable_styling(full_width = FALSE)
```

As a couple of added tips, the extracted table is produced using `fixef(brms.us)` and the coefficients are, of course, logits. If you wanted to easily produce odds you can wrap the aforementioned function with an exponential function `exp(fixef(brms.us))`. You can also easily produce graphs of the marginal effects in the regression model using `marginal_effects(brms.us)`.

## Modelling New Zealand data (NZHS)

We will break the following section up by first constructing the priors, running the same model in the NZ data that we presented above, then running a more complex mediation analysis. The code we are describing is presented in the `nzModel.R` script. You can start by loading the NZ data with the following code.

```{r}
syntheticNz <- readRDS("data/syntheticNz.RDS")
```

### Constructing priors

In our paper, we discuss using the coefficients and error terms from our US sample as priors for the NZ sample. However, we acknowledge that the two countries are quite different and we therefore decrease our certainty of the US based priors by doubling the error terms. We present the original priors used in our paper, but you can easily adjust them to the priors in the sample data or any other reasonably prior you have in mind. You can multiply the error terms easily with `fixef(brms.us)[,2] * 2`.

```{r priorsNz}
priors <- c(
  prior("normal(-0.19, 0.06)", coef="age"),
  prior("normal(0.23, 0.26)", coef="sexM"),
  prior("normal(-0.19, 0.06)", coef="nzdep2013"),
  prior("normal(1.64, 0.55)", coef="sexidentGayDLesbian"),
  prior("normal(1.20, 0.60)", coef="sexidentBisexual"),
  prior("normal(-0.4, 1.1)", coef="sexM:sexidentGayDLesbian"),
  prior("normal(-0.07, 0.8)", coef="sexM:sexidentBisexual")
)
```

It's worth noting that the NZ sample has a slightly different structure and one additional variable (hazardous drinking status):

1. sexident - Sexual identity; Heterosexual, Homosexual, or Bisexual
2. age - Continuous years of age
3. nzdep2013 - A decile score for the house the made up response comes from (higher is better)
4. sex - Categorical variable either male (M) or female (F)
5. k10high - Is a binomial variable denoting an experience of psychological distress in the last six months, either no stress (0) or stress (1)
6. hazardous - Is a binomial variable referring to whether someone reported a hazardous level of drinking

### Basic model

Our basic NZ model looks almost exactly the same as our US model. However, we have also used the option `sample_prior = "yes"` which will create a distribution for our prior. This is helpful for determining how much your posterior is being influenced by the priors. In the supporting R script, you will also see we have a naive model which will perform similarly to a classical logistic regression. This allows us to compare our informed analysis to a non-informed/naive analysis to understand how much credibility we gain from the use of priors[^3].

[^3]:You may also note that our naive model used the prior, `prior("normal(0, 5)", class = "b")`. Similar to the US model, this prior increases sampling efficiency to reduce run time. Interestingly, you would implement regularization in a similar way but typically with a smaller standard diviation. This can be very useful when you observe model separation in logistic regression or when you have a large number of parameters.

```{r modelNz, cache=TRUE}
brms.nz <- brm(
  k10high ~ age + sex * sexident + nzdep2013,
  family = bernoulli(),
  prior = priors,
  sample_prior = "yes",
  cores = 4,
  chains = 4,
  data=syntheticNz
  )
```

```{r modelNz.naive, cache=TRUE, include=FALSE}
brms.nz.naive <- brm(
  k10high ~ age + sex * sexident + nzdep2013,
  family = bernoulli(),
  prior = prior("normal(0, 5)", class = "b"),
  cores = 4,
  chains = 4,
  data=syntheticNz
  )

```

In order to compare differences, we have created a plot with the non-informed and informed coefficients. We can see that the credibility intervals are much smaller when we use informed priors, even though we inflated the error terms on our priors. You can investigate the coefficients between both models using `summary()` or see the rmarkdown document in the GitHub repo to see how we produced the plot below (intermediate knowledge of `tidyverse` required).

```{r compareGraph, echo=FALSE}
nonInformed <- fixef(brms.nz.naive) %>% 
  as.data.frame() %>% 
  mutate(
    Variable = rownames(.), 
    Model = "non-informed"
    )

fixef(brms.nz) %>% 
  as.data.frame() %>% 
  mutate(
    Variable = rownames(.), 
    Model = "informed"
    ) %>%
  bind_rows(nonInformed) %>%
  filter(Variable != "Intercept") %>%
  ggplot(aes(x=Variable, y=Estimate, ymin=Q2.5, ymax=(Q97.5), group=Model, color=Model, linetype=Model, shape=Model)) +
  geom_point() +
  geom_errorbar() +
  coord_flip() +
  labs(title="Figure 1. Comparison of coefficients from informative and non-informative models of the synthetic NZ sample")
```

Figure 1. indicates how influence our priors have, if the midpoints of our coefficients have huge shifts between an informed and non-informed model, we may want to adjust our priors by increasing the error. Another way to visualise the effect of the priors is using the `hypothesis()` function in the `brms` package. You can test your assumption that an effect has over a give probability, or is higher than some other distribution (e.g. an alternatively hypothesised model). See below we plot the prior and posterior distributions for the effect of homosexuals having greater than log odds of zero in regards to their risk of stress. In Figure 1., we see the informed coefficient and its credible interval sit within the non-informed credible interval, then in Figure 2., we see the posterior sits within the prior. We may also consider it evidence that the prior is not being too informative because the posterior has less variance than the prior, as opposed to the posterior taking the exact same form of the prior. 

```{r priorGraph}
plot(hypothesis(brms.nz, "sexidentGayDLesbian > 0"))
```

Any other effects can be tested in the same way, and you can also conduct a sensitivity analysis by re-running models with different priors. Running a range of different priors will give richer information into how the posterior is being affected by our prior information in the context of our observed NZ dataset.

### Mediation model

When using informed priors, your models do not necessarily need to be identical. We have already mentioned that the variables can differ conceptually, such as family income in the US data and deprivation index in the NZ data. However, we can go further and apply information from a simple logistic regression model (US model) and apply it to a more complex structural equation model, e.g., a simple mediation (Figure X).

<center>![mediationModel](walkthroughDocument_files/mediation.svg)</center>

In this example, we wanted to determine if, and to what extent, stress could mediate the relationship between SM status and hazardous drinking in the New zealand population. We calculated the mediation effect using the Sobel product of coefficients (`a` path multiplied by `b` path). Our US data can inform our `b` path and its covariates, which can then decrease the variance in our mediation effect.

In `brms` we can include multiple regressions within the same model by wrapping the `bf()` function around each equation. We can run a simple mediation by using the following layout.

```{r exampleMed, eval=FALSE}
brm(
  bf(outcome ~ mediator + treatment + covariates) + 
    bf(mediator ~ treatment + covariates),
  priors = priors,
  family = distribution(),
  data = df
  )
```

In the NZ mediation model, we can use the same priors used previously except we need to specify which equation the priors address, using the `resp` argument.

```{r appliedMed, cache=TRUE}

# Same priors, using the 'resp' argument
priors_mediation <- c(
  prior("normal(-1.97, 0.5)", coef="age", resp="k10high"),
  prior("normal(-0.29, 0.1)", coef="sexM", resp="k10high"),
  prior("normal(-0.91, 0.4)", coef="nzdep2013", resp="k10high"),
  prior("normal(1.03, 0.18)", coef="sexidentGayDLesbian", resp="k10high"),
  prior("normal(1.18, 0.18)", coef="sexidentBisexual", resp="k10high"),
  prior("normal(-0.07, 0.2)", coef="sexM:sexidentGayDLesbian", resp="k10high"),
  prior("normal(-0.01, 0.2)", coef="sexM:sexidentBisexual", resp="k10high")
)

# Mediation model using NZ data
brm.mediation <- brm(
  bf(hazardous ~ k10high + age + sex * sexident + nzdep2013) +
    bf(k10high ~ age + sex * sexident + nzdep2013),
  prior = priors_mediation,
  family = bernoulli(),
  chains = 4,
  cores = 4,
  data = syntheticNz
)
```

Now that we have our results, it is relatively straight forward to estimate a mediating effect (skip ahead if you want a mediating effect but already know, or dont want to know, the details. Bayesian models with MCMC will product a large number of samples with form the posterior distribution. If we multiple the samples from our `a` path and `b` path, then we have a posterior distribution representing our mediation effect (`ab`). The direct effect is simple the `c'` path, meaning the total effect, `c`, is `ab` + `c`. If we divide our mediation effect by the total effect, we can get the proportion mediated (`ab` / `c`). This is a very similar process to a bootstrap approach within a frequentist framework.

In summary...

* `a` is the coefficient for the effect of SM status on stress
* `b` is the coefficient for the effect of stress on hazardous drinking
* `c'` is the coefficient for the effect of SM status on hazardous drinking _while controlling for stress_, and is often called the **direct effect**

We can use the MCMC samples to estimate distributions for each effect as follows...

* `ab` is just samples for `a` and `b` multiplied together and gives the **indirect effect**
* `c` is derived by adding `ab` and `c` to give the **total effect**
* **proportion mediated** is calculated by dividing the **indirect effect** by the **total effect**

In practice, we can use a convenient function form the `sjstats` package that will calculate everything for us. As sexual identity is categorical, we need to enter each separately.

```{r mediatingEffect}
sjstats::mediation(
  brm.mediation,
  treatment = "sexidentGayDLesbian",
  mediator = "k10high",
  prob = 0.95)

sjstats::mediation(
  brm.mediation,
  treatment = "sexidentBisexual",
  mediator = "k10high",
  prob = 0.95)
```

We now run a naive analysis and constructed some code to convert our outputs to a dataframe for graphing. We see in the output below, the 95% credible interval and median for each effect is ploted seperately and compared between non-informed and informed models. Unsurprisingly, we see no difference in the direct effect, which had no priors. However, there is a large reduction in the credible intervals for the indirect effect. Recall we had priors for the `a` path, and the indirect effect is the product of the `a` and `b` paths. It should also be intuitive that our total effect and proportion mediated are also reduced for a similar reason.

```{r naiveMediation, cache=TRUE}
brm.mediation.naive <- brm(
  bf(hazardous ~ k10high + age + sex * sexident + nzdep2013) +
    bf(k10high ~ age + sex * sexident + nzdep2013),
  prior = prior("normal(0, 5)", class="b"),
  family = bernoulli(),
  chains = 4,
  cores = 4,
  data = syntheticNz
)
```

```{r plots}
mediation_data <- bind_rows(
  sjstats::mediation(
  brm.mediation,
  treatment = "sexidentGayDLesbian",
  mediator = "k10high",
  prob = 0.95) %>%
  data.frame() %>%
  mutate(identity = "homosexual",
         model = "informed"
         ),
sjstats::mediation(
  brm.mediation,
  treatment = "sexidentBisexual",
  mediator = "k10high",
  prob = 0.95) %>%
  data.frame() %>%
  mutate(identity = "bisexual",
         model = "informed"
         ),
sjstats::mediation(
  brm.mediation.naive,
  treatment = "sexidentGayDLesbian",
  mediator = "k10high",
  prob = 0.95) %>%
  data.frame() %>%
  mutate(identity = "homosexual",
         model = "non-informed"
         ),
sjstats::mediation(
  brm.mediation.naive,
  treatment = "sexidentBisexual",
  mediator = "k10high",
  prob = 0.95) %>%
  data.frame() %>%
  mutate(identity = "bisexual",
         model = "non-informed"
         )
)

mediation_data %>%
  filter(effect != "mediator") %>%
  ggplot(aes(x=identity, y=value, ymin=hdi.low, ymax=hdi.high, group=model, color=model, linetype=model)) +
  geom_point() +
  geom_errorbar() +
  facet_wrap(~effect,
             scales="free_y")
```

## Conclusions

In this walkthrough, we have given a brief overview on how to run a basic Bayesian logistic regression, and use results to inform a similar analysis on a smaller sample. The method is quite generalisable, in that you could run a regular regression model by using `normal()` instead of `bernoulli()` and could use any combination of covariates and levels of informativeness. In a more thorough approach, however, we would also advise conducting a sensitivity analysis. In a sensitivity analysis, you can use different levels of informativeness to understand the impact of your priors, and it is simple, albeit time consuming to complete. When conducting your own study, produce the non-informed analysis at a minimum and then you could also consider attaching the sensitivity analyses as a supplementary or make it available via OSF or GitHub (the latter if you wish to include the models which can be quite large).

Consult the short `R` code we have made available and tweak it to understand what is happening. Also use summary functions such as `marginal_effects()` and `summary()` to further investigate models produced from our sample data.