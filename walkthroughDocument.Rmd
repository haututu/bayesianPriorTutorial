---
title: "Example construction of informative Bayesian priors for substance research with minority groups"
author: "Taylor Winter"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
opts_chunk$set(echo = TRUE)

theme_set(theme_classic())
```

## Overview

This document is a walkthrough for an associated tutorial manuscript in review with the journal Addiction[^1] and accompanies `R` code in the following [GitHub repository](https://github.com/haututu/bayesianPriorTutorial). We use a large dataset to investigate if sexual minorities (SMs) are at higher risk of psychological distress relative to non-SMs (nSMs). We then constract priors based on the large survey model and run a similar model using a smaller survey. Lastly, we use priors to inform part of a mediation analysis to get a more reliable understanding on how much stress can mediate the increased likelihood of hazarous drinking expressed by SMs relative to nSMs. 

In the associated manuscript, we used the [National Survey on Drug Use and Health](https://nsduhweb.rti.org/respweb/homepage.cfm) (NSDUH; n=83,661) to inform our smaller survey, the [New Zealand Health Survey](https://www.health.govt.nz/nz-health-statistics/national-collections-and-surveys/surveys/new-zealand-health-survey) (NZHS, n=24098). In the former case, the dataset is huge, and in the latter, the data is provided by application only. Hence, we have created created smaller datasets that will show similar trends as presented in our study albeit with slightly different coefficients (See `makeSyntheticData.R` for details on how we created datasets).

The analysis relies on the `tidyverse` and a Bayesian regression package called `brms`[^2]. This document does not cover these packages and we would encourage readers to consult the `brms` vignettes or any basic R tutorials for `tidyverse` walkthroughs.

[^1]: Winter, T., Riordan, B., Surace, A., & Jose, P. (In Review). A comparison of Bayesian and classical statistics for substance research with sexual minorities

[^2]: Paul-Christian BÃ¼rkner (2017). brms: An R Package for Bayesian Multilevel Models Using Stan. Journal of
  Statistical Software, 80(1), 1-28. doi:10.18637/jss.v080.i01

## Modelling the United States data (NSDUH)

We start with the script named `usModel.R`, by loading the neccesary libraries and the `syntheticUs.RDS` file. You can now check and plot the data if you wish. The data contains five variables:

1. SEXIDENT - Sexual identity; Heterosexual (1), Homosexual (2), or Bisexual(3)
2. AGE2 - A ordinal variable with different age groupings (labels attached to variable)
3. IRFAMIN3 - Total family income as an ordinal variable (labels attached to variable)
4. IRSEX - Categorical variable either male (1) or female (2)
5. SPDMON - Is a binomial variable denoting an experience of psychological distress in the last six months, either no stress (0) or stress (1)

```{r readUs, message=FALSE}
library(tidyverse)
library(brms)

syntheticUs <- readRDS("data/syntheticUs.RDS") %>%
  sample_frac(0.4)
```

### Constructing priors

We then construct some simple weak priors for the logistic regression, this is out of neccesity because the dataset is so huge in our study that it would take a day to run. When using Stan as your MCMC sampler, even very week priors can have a major impact on your convergence time without influencing your posterior at all.

We are specifying priors as normal distributions, for example the coefficient `IRSEX2` has a normal distrtribution with a mean of one and standard deviation of one (note the scale is log odds for logistic regression). This means we believe the odds of females having higher stress than males has 95% probability of falling between an odds of 0.14 and 7.38... it shoudl be particularly obvious why this prior would not impact on our posterior but certainly rules out a large range of increadibly unlikely odds ratios.

A further point you may note below, is that the age and income vairables start with `mo~`. This is short for monotonic, which is a type of mathematical function that allows you to model ordered variables. As we are using monotonic functions in our `brms` model, our variables gain the `mo~` prefix. Similarly, as sex is a categorical variable, the effect of females is modelled in reference to males and we therefore add the suffix `~2` to acknowledge this fact.


```{r priorsUs}
priors <- c(prior("normal(1, 1)", coef="IRSEX2"),
            prior("normal(-1, 1)", coef="moAGE2"),
            prior("normal(-1, 1)", coef="moIRFAMIN3"))

```

### Basic model

We can now model the US data. If you're familiar with `lme4` syntax then this is quite straight forward, we model stress (SPDMON) as a covariate with age (AGE2), sex (IRSEX), SM status (sexident), and family income (IRFAMIN3) as predictors. As mentioned, age and family income are ordinal variables and we capture this relationship by modelling a  monotonic effect, implemented by wrapping the variable with the `mo()` function.

We then specify the family (response distribution), in this case we want a Bernoulli distribution which will conduct a traditional logistic regression. We parse our priors, and want to sample four chains across four CPU cores. It will take about five minutes to run. Feel free to reflect on our pain when running a sample of over 80,000 during this time.

```{r modelUs, cache=TRUE}
brms.us <- brm(
  SPDMON ~ mo(AGE2) + IRSEX * SEXIDENT + mo(IRFAMIN3),
  family = bernoulli(),
  prior = prior("normal(0, 2)", class="b"),
  cores = 4,
  chains = 4,
  data=syntheticUs
  )
```

Finally, we can see the results of our logistic regression using the `summary(brms.us)` function. It will output a bunch of simplex parameters which are pertaining to our monotonic effects, feel free to ignore them and focus on the population-level effects for the purpose of this walkthrough. The population-level effects that will form the basis of our priors for the NZ data. You will see in the table below we have extracted only the fixed effects (Table 1).

```{r fixef, echo=FALSE}
fixef(brms.us) %>%
  kable(caption = "<b>Table 1.</b> Fixed effects for the logistic regression model using US data") %>%
  kable_styling(full_width = FALSE)
```

As a couple of added tips, the extracted table is produced using `fixef(brms.us)` and the coefficients are, of course, logits. If you wanted to easily produce odds you can wrap the aforementioned function with an exponential function `exp(fixef(brms.us))`. You can also easily produce graphs of the marginal effects in the regression model using `marginal_effects(brms.us)`.

## Modelling New Zealand data (NZHS)

We will break the following section up by first constructing the priors, running the same model in the NZ data that we presented above, then running a more complex mediation analysis. The code we are describing is presented in the `nzModel.R` script. You can start by loading the NZ data with the following code.

```{r}
syntheticNz <- readRDS("data/syntheticNz.RDS")
```

### Constructing priors

In our paper, we discuss using the coefficients and error terms from our US sample as priors for the NZ sample. However, we acknowledge that the two countries are quite different and we therefore decrease our certainty of the US based priors by doubling the error terms. We present the original priors used in our paper, but you can easily adjust them to the priors in the sample data or any other reasonably prior you have in mind. You can multiply the error terms easily with `fixef(brms.us)[,2] * 2`.

```{r priorsNz}
priors <- c(
  prior("normal(-0.19, 0.06)", coef="age"),
  prior("normal(0.23, 0.26)", coef="sexM"),
  prior("normal(-0.19, 0.06)", coef="nzdep2013"),
  prior("normal(1.64, 0.55)", coef="sexidentGayDLesbian"),
  prior("normal(1.20, 0.60)", coef="sexidentBisexual"),
  prior("normal(-0.4, 1.1)", coef="sexM:sexidentGayDLesbian"),
  prior("normal(-0.07, 0.8)", coef="sexM:sexidentBisexual")
)
```

It's worth noting that the NZ sample has a slightly different structure and one additional variable (hazardous drinking status):

1. sexident - Sexual identity; Heterosexual, Homosexual, or Bisexual
2. age - Continuous years of age
3. nzdep2013 - A decile score for the house the made up response comes from (higher is better)
4. sex - Categorical variable either male (M) or female (F)
5. k10high - Is a binomial variable denoting an experience of psychological distress in the last six months, either no stress (0) or stress (1)
6. hazardous - Is a binomial variable referring to whether someone reported a hazardous level of drinking

### Basic model

Our basic NZ model looks almost exactly the same as our US model. However, we have also used the option `sample_prior = "yes"` which will create a distribution for our prior. This is helpful for determining how much your posterior is being influenced by the priors. In the supporting R script, you will also see we have a naive model which will perform similarly to a classical logistic regression. This allows us to compare our informed analysis to a non-informed/naive analysis to understand how much credibility we gain from the use of priors[^3].

[^3]:You may also note that our naive model used the prior, `prior("normal(0, 5)", class = "b")`. Similar to the US model, this prior increases sampling efficiency to reduce run time. Interestingly, you would implement regularization in a similar way but typically with a smaller standard diviation. This can be very useful when you observe model separation in logistic regression or when you have a large number of parameters.

```{r modelNz, cache=TRUE}
brms.nz <- brm(
  k10high ~ age + sex * sexident + nzdep2013,
  family = bernoulli(),
  prior = priors,
  sample_prior = "yes",
  cores = 4,
  chains = 4,
  data=syntheticNz
  )
```

```{r modelNz.naive, cache=TRUE, include=FALSE}
brms.nz.naive <- brm(
  k10high ~ age + sex * sexident + nzdep2013,
  family = bernoulli(),
  prior = prior("normal(0, 5)", class = "b"),
  cores = 4,
  chains = 4,
  data=syntheticNz
  )

```

In order to compare differences, we have created a plot with the non-informed and informed coefficients. We can see that the credibility intervals are much smaller when we use informed priors, even though we inflated the error terms on our priors. You can investigate the coefficients between both models using `summary()` or see the rmarkdown document in the GitHub repo to see how we produced the plot below (intermediate knowledge of `tidyverse` required).

```{r compareGraph, echo=FALSE}
nonInformed <- fixef(brms.nz.naive) %>% 
  as.data.frame() %>% 
  mutate(
    Variable = rownames(.), 
    Model = "non-informed"
    )

fixef(brms.nz) %>% 
  as.data.frame() %>% 
  mutate(
    Variable = rownames(.), 
    Model = "informed"
    ) %>%
  bind_rows(nonInformed) %>%
  filter(Variable != "Intercept") %>%
  ggplot(aes(x=Variable, y=Estimate, ymin=Q2.5, ymax=(Q97.5), group=Model, color=Model, linetype=Model, shape=Model)) +
  geom_point() +
  geom_errorbar() +
  coord_flip() +
  labs(title="Figure 1. Comparison of coefficients from informative and non-informative models of the synthetic NZ sample")
```

Figure 1. indicates how influence our priors have, if the midpoints of our coefficients have huge shifts between an informed and non-informed model, we may want to adjust our priors by increasing the error. Another way to visualise the effect of the priors is using the `hypothesis()` function in the `brms` package. You can test your assumption that an effect has over a give probability, or is higher than some other distribution (e.g. an alternatively hypothesised model). See below we plot the prior and posterior distributions for the effect of homosexuals having greater than log odds of zero in regards to their risk of stress. In Figure 1., we see the informed coefficient and its credible interval sit within the non-informed credible interval, then in Figure 2., we see the posterior sits within the prior. We may also consider it evidence that the prior is not being too informative because the posterior has less variance than the prior, as opposed to the posterior taking the exact same form of the prior. 

```{r priorGraph}
plot(hypothesis(brms.nz, "sexidentGayDLesbian > 0"))
```

Any other effects can be tested in the same way, and you can also conduct a sensitivity analysis by re-running models with different priors. Running a range of different priors will give richer information into how the posterior is being affected by our prior information in the context of our observed NZ dataset.

### Mediation model

## Conclusions